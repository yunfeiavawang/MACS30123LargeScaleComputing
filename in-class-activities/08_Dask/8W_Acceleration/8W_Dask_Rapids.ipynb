{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "scfLT2i0MLyD"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1nCh7YtUZ4vqCxkdpV5PrqhfZIxvowMr_?usp=sharing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "# Accelerating Dask with GPUs (via RAPIDS)\n",
        "\n",
        "We've seen in lecture how the RAPIDS libraries make it possible to accelerate common analytical workflows on GPUs using libraries like cudf (for GPU DataFrames) and cuml (for basic GPU machine learning operations on DataFrames). When your data gets especially large (e.g. exceeding the memory capacity of a single GPU) or your computations get especially cumbersome, Dask makes it possible to scale these workflows out even further -- distributing work out across a cluster of GPUs.\n",
        "\n",
        "In AWS Academy, recall that we cannot create GPU clusters. However, this notebook should also be runnable on multi-GPU EC2 instances and clusters (on AWS) if you use a personal account to request these resources. Here (on Colab), we'll demonstrate using a single GPU. Note that the setup portion of this notebook draws on [a setup notebook](https://colab.research.google.com/drive/13sspqiEZwso4NYTbsflpPyNFaVAAxUgr) linked in the RAPIDS documentation and is meant to be run in a Colab notebook.\n",
        "\n",
        "This demo is built off of the notebooks provided in the [RAPIDS notebook repositories](https://github.com/rapidsai/notebooks) on GitHub (and you can explore them further if you are interested! There are many other relevant libraries in the RAPIDS ecosystem -- e.g. `cugraph` which allows you to perform network analyses on GPUs).\n",
        "\n",
        "## Setup\n",
        "\n",
        "Click the _Runtime_ dropdown at the top of the page, then _Change Runtime Type_ and confirm the instance type is _GPU_.\n",
        "\n",
        "Check the output of `!nvidia-smi` to make sure you've been allocated a Tesla T4, P4, or P100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67T0090Jk2KL",
        "outputId": "7eb74a98-1a59-4d0e-ec2a-20d9a16e8743",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun May  7 17:49:44 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CtNdk7PSafKP"
      },
      "source": [
        "Then we run the setup script below, which:\n",
        "\n",
        "1. Checks to make sure that the GPU is RAPIDS compatible\n",
        "1. Installs the **current stable version** of RAPIDSAI's core libraries using pip and **will complete in about 3-4 minutes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0C8IV5TQnjN",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!python rapidsai-csp-utils/colab/pip-install.py"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pZJMJ6BulmMn"
      },
      "source": [
        "At this point, our RAPIDS libraries are now installed on Colab and we can import them into our session. Let's use `dask_cuda`'s API to launch a Dask GPU cluster and pass this cluster object to our `dask.distributed` client. `LocalCUDACluster()` will count each available GPU in our cluster (in this case, 1 GPU) as a Dask worker and assign it work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NtKgmG5yrK0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "from dask_cuda import LocalCUDACluster\n",
        "from dask.distributed import Client\n",
        "\n",
        "cluster = LocalCUDACluster() # Identify all available GPUs\n",
        "client = Client(cluster)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "chi0hJp96DH2"
      },
      "source": [
        "## GPU DataFrames\n",
        "\n",
        "From here, we can use `dask_cudf` to automate the process of partitioning our data across our GPU workers and instantiating a GPU-based DataFrame on our GPU that we can work with. Let's load in the same AirBnB data that we were working with in the `numba` + `dask` CPU demonstration:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "unMBP-Y2zneS",
        "outputId": "750f621b-857b-4c5d-f0d2-5cfb5fe0dfc7",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>host_id</th>\n",
              "      <th>host_name</th>\n",
              "      <th>neighbourhood_group</th>\n",
              "      <th>neighbourhood</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>room_type</th>\n",
              "      <th>price</th>\n",
              "      <th>minimum_nights</th>\n",
              "      <th>number_of_reviews</th>\n",
              "      <th>last_review</th>\n",
              "      <th>reviews_per_month</th>\n",
              "      <th>calculated_host_listings_count</th>\n",
              "      <th>availability_365</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3781</td>\n",
              "      <td>HARBORSIDE-Walk to subway</td>\n",
              "      <td>4804</td>\n",
              "      <td>Frank</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>East Boston</td>\n",
              "      <td>42.36413</td>\n",
              "      <td>-71.02991</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>125</td>\n",
              "      <td>32</td>\n",
              "      <td>19</td>\n",
              "      <td>2021-02-26</td>\n",
              "      <td>0.27</td>\n",
              "      <td>1</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6695</td>\n",
              "      <td>$99 Special!! Home Away! Condo</td>\n",
              "      <td>8229</td>\n",
              "      <td>Terry</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>Roxbury</td>\n",
              "      <td>42.32802</td>\n",
              "      <td>-71.09387</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>169</td>\n",
              "      <td>29</td>\n",
              "      <td>115</td>\n",
              "      <td>2019-11-02</td>\n",
              "      <td>0.81</td>\n",
              "      <td>4</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10813</td>\n",
              "      <td>Back Bay Apt-blocks to subway, Newbury St, The...</td>\n",
              "      <td>38997</td>\n",
              "      <td>Michelle</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>Back Bay</td>\n",
              "      <td>42.35061</td>\n",
              "      <td>-71.08787</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>96</td>\n",
              "      <td>29</td>\n",
              "      <td>5</td>\n",
              "      <td>2020-12-02</td>\n",
              "      <td>0.08</td>\n",
              "      <td>11</td>\n",
              "      <td>307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10986</td>\n",
              "      <td>North End (Waterfront area)  CLOSE TO MGH &amp; SU...</td>\n",
              "      <td>38997</td>\n",
              "      <td>Michelle</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>North End</td>\n",
              "      <td>42.36377</td>\n",
              "      <td>-71.05206</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>96</td>\n",
              "      <td>29</td>\n",
              "      <td>2</td>\n",
              "      <td>2016-05-23</td>\n",
              "      <td>0.03</td>\n",
              "      <td>11</td>\n",
              "      <td>293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13247</td>\n",
              "      <td>Back Bay studio apartment</td>\n",
              "      <td>51637</td>\n",
              "      <td>Susan</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>Back Bay</td>\n",
              "      <td>42.35164</td>\n",
              "      <td>-71.08752</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>75</td>\n",
              "      <td>91</td>\n",
              "      <td>0</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                               name  host_id  \\\n",
              "0   3781                          HARBORSIDE-Walk to subway     4804   \n",
              "1   6695                     $99 Special!! Home Away! Condo     8229   \n",
              "2  10813  Back Bay Apt-blocks to subway, Newbury St, The...    38997   \n",
              "3  10986  North End (Waterfront area)  CLOSE TO MGH & SU...    38997   \n",
              "4  13247                          Back Bay studio apartment    51637   \n",
              "\n",
              "  host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
              "0     Frank                <NA>   East Boston  42.36413  -71.02991   \n",
              "1     Terry                <NA>       Roxbury  42.32802  -71.09387   \n",
              "2  Michelle                <NA>      Back Bay  42.35061  -71.08787   \n",
              "3  Michelle                <NA>     North End  42.36377  -71.05206   \n",
              "4     Susan                <NA>      Back Bay  42.35164  -71.08752   \n",
              "\n",
              "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
              "0  Entire home/apt    125              32                 19  2021-02-26   \n",
              "1  Entire home/apt    169              29                115  2019-11-02   \n",
              "2  Entire home/apt     96              29                  5  2020-12-02   \n",
              "3  Entire home/apt     96              29                  2  2016-05-23   \n",
              "4  Entire home/apt     75              91                  0        <NA>   \n",
              "\n",
              "  reviews_per_month  calculated_host_listings_count  availability_365  \n",
              "0              0.27                               1               106  \n",
              "1              0.81                               4                40  \n",
              "2              0.08                              11               307  \n",
              "3              0.03                              11               293  \n",
              "4              <NA>                               2                 0  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import dask_cudf\n",
        "\n",
        "df = dask_cudf.read_csv('listings*.csv')\n",
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VpQhPunk6m4F"
      },
      "source": [
        "Once we have that data, we can perform many of the standard DataFrame operations we perform on CPUs -- just accelerated by our GPU cluster!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkiHccaP5x47",
        "outputId": "1c38e37f-831d-420b-b581-3fe1b00d6c07",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "neighbourhood   room_type      \n",
              "North Center    Private room        75.818182\n",
              "Clearing        Entire home/apt     90.000000\n",
              "Edgewater       Entire home/apt    140.142857\n",
              "South Lawndale  Entire home/apt     79.826087\n",
              "Auburn Gresham  Entire home/apt    135.000000\n",
              "                                      ...    \n",
              "Lakeshore       Entire home/apt    205.500000\n",
              "Brighton Park   Shared room         39.000000\n",
              "Lake View       Hotel room         656.400000\n",
              "North Beach     Shared room         31.900000\n",
              "Ashburn         Entire home/apt    100.857143\n",
              "Name: price, Length: 341, dtype: float64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.groupby(['neighbourhood', 'room_type']) \\\n",
        "  .price \\\n",
        "  .mean() \\\n",
        "  .compute()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "a7KLwLyB64jv"
      },
      "source": [
        "One thing to note, though, is that not all of the functionality we might expect out of CPU clusters is available yet in the `cudf`/`dask_cudf` DataFrame implementation.\n",
        "\n",
        "For instance (and of particular note!), our ability to apply custom functions is still pretty limited. `cudf` uses Numba's CUDA compiler to translate this code for the GPU and [many standard `numpy` operations are not supported](https://numba.pydata.org/numba-doc/dev/cuda/cudapysupported.html#numpy-support) (for instance, if you try to apply the distance calculation with performed in the Numba+Dask CPU demonstration notebook for today, this will fail to compile correctly for the GPU).\n",
        "\n",
        "That being said, we can perform many base-Python operations inside of custom functions, so if you can express your custom functions in this way, it might be worth your while to do this work on a GPU. For example, let's create a custom price index that indicates whether an AirBnB is \\\"Cheap\\\" (0), \\\"Moderately Expensive\\\" (1), or \\\"Very Expensive\\\" (2) using `cudf`'s [`apply_rows` method](https://docs.rapids.ai/api/cudf/stable/user_guide/guide-to-udfs.html#numba-kernels-for-dataframes):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QxM3nfk26tA6",
        "outputId": "7a98fa7e-264d-46bf-f335-896ac23fd5bc",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>price_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>125</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>169</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>96</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>96</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>75</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   price  price_index\n",
              "0    125            2\n",
              "1    169            2\n",
              "2     96            1\n",
              "3     96            1\n",
              "4     75            1"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def expensive(x, price_index):\n",
        "    # passed through Numba's CUDA compiler and `for`\n",
        "    # loop is automatically parallelized for GPU\n",
        "    for i, price in enumerate(x):\n",
        "        if price < 50:\n",
        "            price_index[i] = 0\n",
        "        elif price < 100:\n",
        "            price_index[i] = 1\n",
        "        else:\n",
        "            price_index[i] = 2\n",
        "\n",
        "# Use cudf's `apply_rows` API for applying function to every row in DataFrame\n",
        "df = df.apply_rows(expensive,\n",
        "                   incols={'price':'x'},\n",
        "                   outcols={'price_index': int},\n",
        "                   kwargs={})\n",
        "\n",
        "# Confirm that price index created correctly\n",
        "df[['price', 'price_index']].head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LVSSbc6v8tp3"
      },
      "source": [
        "## Training Machine Learning Models with `cuml`\n",
        "\n",
        "In addition to preprocessing and analyzing data on GPUs, we can also train (a limited set of) Machine Learning models directly on our GPU cluster using the `cuml` library in the RAPIDS ecoystem as well. This can give us a significant speedup in training time over libraries like `sklearn` on CPUs for large datasets.\n",
        "\n",
        "For instance, let's train a linear regression model based on our data from San Francisco, Chicago, and Boston to predict the price of an AirBnB based on other values in its listing information (e.g. \\\"reviews per month\\\" and \\\"minimum nights\\\"). We'll then use this model to make predictions about the price of AirBnBs in another city (NYC):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUEWhXoY4Q4a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from cuml.dask.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "X = df[['reviews_per_month', 'minimum_nights']].astype(np.float32).dropna()\n",
        "y = df[['price']].astype(np.float32).dropna()\n",
        "fit = LinearRegression().fit(X, y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "e_fDVoXbWlRo"
      },
      "source": [
        "Then, we can read in the NYC dataset and make predictions about what prices will be in NYC on the basis of the model we trained on data from our three original cities:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIsYyeFA4TsM",
        "outputId": "d52d0a4b-ff7a-4a86-f8db-27376db47b54",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    184.802887\n",
              "1    188.286636\n",
              "2    184.802887\n",
              "3    183.658218\n",
              "4    186.646774\n",
              "dtype: float32"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_nyc = dask_cudf.read_csv('test*.csv')\n",
        "X_test = df_nyc[['reviews_per_month', 'minimum_nights']].astype(np.float32) \\\n",
        "                                                        .dropna()\n",
        "fit.predict(X_test) \\\n",
        "   .compute() \\\n",
        "   .head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ywgOnAx4KN9s"
      },
      "source": [
        "If we take a look at other standard machine learning algorithms in the documentation (for instance [k means clustering](https://github.com/rapidsai/cuml/blob/branch-23.04/notebooks/kmeans_demo.ipynb)) as well, we can see significant speedups over performing the same operations on large datasets in scikit-learn on a CPU.\n",
        "\n",
        "Note, though, that this is only true of larger data. For smaller data sizes, we will see comparable performance on CPU and GPUs. **Ask:** why?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
