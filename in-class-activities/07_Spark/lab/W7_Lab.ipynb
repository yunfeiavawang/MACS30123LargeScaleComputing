{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MACS 30113/30123 Lab Session: Working with EMR Clusters/Spark\n",
    "*Week 6*\n",
    "\n",
    "**Adam Wu, Wonje Yun**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create S3 Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create S3 bucket to store our files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T22:57:55.401001Z",
     "start_time": "2024-05-06T22:57:55.391513Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T22:57:57.308009Z",
     "start_time": "2024-05-06T22:57:56.903779Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize boto3 handler\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "# Create a new bucket to store your files\n",
    "BUCKETNAME = 'adam-example-bucket'\n",
    "s3.create_bucket(Bucket=BUCKETNAME)\n",
    "\n",
    "# This is what we will use to interface with the specific bucket\n",
    "bucket = s3.Bucket( BUCKETNAME )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T22:58:08.783183Z",
     "start_time": "2024-05-06T22:58:08.543064Z"
    }
   },
   "outputs": [],
   "source": [
    "# Upload your .py file to S3\n",
    "\n",
    "FILENAME = 'mystuff/myfile.py'\n",
    "with open('mystuff/myfile.py', 'rb') as myfile:\n",
    "    bucket.put_object(Key=FILENAME, Body=myfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launching EMR Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next launch EMR Cluster in Terminal/bash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T22:24:59.258263Z",
     "start_time": "2024-05-06T22:24:56.359573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"ClusterId\": \"j-2GGSSO7FCKI2X\",\n",
      "    \"ClusterArn\": \"arn:aws:elasticmapreduce:us-east-1:348752177325:cluster/j-2GGSSO7FCKI2X\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "aws emr create-cluster \\\n",
    "    --name \"Spark Cluster\" \\\n",
    "    --release-label \"emr-6.2.0\" \\\n",
    "    --applications Name=Hadoop Name=Hive Name=JupyterEnterpriseGateway Name=JupyterHub Name=Livy Name=Pig Name=Spark Name=Tez \\\n",
    "    --instance-type m5.xlarge \\\n",
    "    --instance-count 3 \\\n",
    "    --use-default-roles \\\n",
    "    --region us-east-1 \\\n",
    "    --ec2-attributes '{\"KeyName\": \"vockey\"}' \\\n",
    "    --configurations '[{\"Classification\": \"jupyter-s3-conf\", \"Properties\": {\"s3.persistence.enabled\": \"true\", \"s3.persistence.bucket\": \"adam-example-bucket\"}}]'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating a new cluster, make sure to adjust the security settings to allow for `ssh` access. See `emr_cheatsheet.md` in Week 7 course materials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1: `ssh` Directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first way to work with EMR is to directly `ssh` into it, then work with it just like we did for `EC2` (see previous lab on EC2).\n",
    "\n",
    "Connecting to it:\n",
    "```\n",
    "$ ssh -i vockey.pem hadoop@EMR-PUBLIC-ADDRESS\n",
    "```\n",
    "\n",
    "Uploading a folder called `mystuff` locally -> EMR:\n",
    "```\n",
    "$ scp -i \"vockey.pem\" -r mystuff hadoop@EMR-PUBLIC-ADDRESS:/home/hadoop\n",
    "```\n",
    "\n",
    "Downloading a folder called `mystuff` from EMR -> locally:\n",
    "```\n",
    "$ scp -i \"vockey.pem\" -r hadoop@EMR-PUBLIC-ADDRESS:/home/hadoop/mystuff .\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After uploading your files in there, you can then run Spark jobs with\n",
    "``` \n",
    "[EMR] spark-submit mystuff/myfile.py\n",
    "```\n",
    "Alternatively if your files are saved on `S3`, then\n",
    "```\n",
    "[EMR] spark-submit s3://adam-example-bucket/mystuff/myfile.py adam-example-bucket\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: Interactive Sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also launch a Jupyter server directly on EMR and work with it interactively.\n",
    "```\n",
    "$ ssh -i \"vockey.pem\" -NL 9443:localhost:9443 hadoop@EMR-PUBLIC-ADDRESS\n",
    "```\n",
    "This forwards the remote connection to your `https://localhost:9443`, and you can log in with username `jovyan`, password `jupyter`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 3: Running Spark on Midway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `sbatch`, refer to `in-class-activities/07_Spark/7M_Spark_EDA_ML/midway` on Week 7 course materials. \n",
    "\n",
    "You can also work with Spark interactive on Midway with `sinteractive`:\n",
    "```bash\n",
    "$ sinteractive --ntasks=<NUMBER-OF-TASKS> --account=macs30123\n",
    "```\n",
    "This would take you into the computation node, where you can start `python3` or `ipython3` directly in the terminal. For Spark, you need to run `pyspark`.\n",
    "```bash\n",
    "$ pyspark\n",
    "```\n",
    "This would start the spark shell and pyspark, where you can work like `python3` in the terminal.\n",
    "To exit from spark shell run:\n",
    "```bash\n",
    "$ exit()\n",
    "```\n",
    "To exit from sinteractive run:\n",
    "```bash\n",
    "$ exit()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
